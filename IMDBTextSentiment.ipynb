{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd5hztyTWWQ8"
      },
      "source": [
        "## ***IMDB Text and Sequence***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDue21juWjbm"
      },
      "source": [
        "*Loading the libraries*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NSOTueQ9iYaw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "from keras.utils.data_utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Embedding, LSTM,  Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.optimizers import adam\n",
        "from google.colab import files\n",
        "import re, os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5qp4wPKKBGH"
      },
      "source": [
        "To Not Display the Warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EUbW4APJ3JJ"
      },
      "outputs": [],
      "source": [
        "# To deprecate warnings that are making the output look clumsy\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmn4wwf6O5CQ"
      },
      "source": [
        "### ***Model 1 - Basic Model (To understand how embedding and cutoff works)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqTunH8Ef0Uj"
      },
      "source": [
        "*We didn't limit the training, validation and test samples here. I ran a basic model with the entire sample strength to know the model's performance.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ob3y9r0Xapm"
      },
      "outputs": [],
      "source": [
        "# Considering only top 10,000 Words\n",
        "max_features = 10000\n",
        "\n",
        "# Setting a Cut-Off Point for Reviews after 150 Words\n",
        "maxlen = 150\n",
        "\n",
        "# Loading the Train and Test Datasets of the IMDB Example\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pre-Processing to Convert the Texts to Numericals\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QRpvxfFPTA4"
      },
      "source": [
        "*Building the Network*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFT6jJtJZVCT"
      },
      "outputs": [],
      "source": [
        "# Setting the Sequential Layer for Model Building\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the Embedding Layer with limiting to consider only the top 10,000 Words\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "\n",
        "# Flattening the Size \n",
        "model.add(Flatten())\n",
        "\n",
        "# Adding the Classifer on the top - As the final layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the Model\n",
        "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bKX-PErPLYn"
      },
      "source": [
        "*Summary of the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kTLxkIfarbV",
        "outputId": "8322baa8-49b1-40da-8976-de3d977c681a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 150, 8)            80000     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1201      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t00yC5tPO1N"
      },
      "source": [
        "*Model Execution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUg0YQCVatLo",
        "outputId": "2c2ef274-72bc-4269-c3d7-392339fb76d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "625/625 [==============================] - 37s 57ms/step - loss: 0.5919 - acc: 0.7059 - val_loss: 0.4172 - val_acc: 0.8318\n",
            "Epoch 2/30\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3307 - acc: 0.8666 - val_loss: 0.3225 - val_acc: 0.8632\n",
            "Epoch 3/30\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.2580 - acc: 0.8959 - val_loss: 0.3054 - val_acc: 0.8696\n",
            "Epoch 4/30\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2235 - acc: 0.9123 - val_loss: 0.3049 - val_acc: 0.8704\n",
            "Epoch 5/30\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.1988 - acc: 0.9237 - val_loss: 0.3105 - val_acc: 0.8708\n",
            "Epoch 6/30\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.1779 - acc: 0.9336 - val_loss: 0.3114 - val_acc: 0.8710\n",
            "Epoch 7/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1593 - acc: 0.9420 - val_loss: 0.3174 - val_acc: 0.8694\n",
            "Epoch 8/30\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1418 - acc: 0.9494 - val_loss: 0.3281 - val_acc: 0.8680\n",
            "Epoch 9/30\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1250 - acc: 0.9562 - val_loss: 0.3444 - val_acc: 0.8674\n",
            "Epoch 10/30\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1086 - acc: 0.9639 - val_loss: 0.3509 - val_acc: 0.8666\n",
            "Epoch 11/30\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0937 - acc: 0.9682 - val_loss: 0.3559 - val_acc: 0.8666\n",
            "Epoch 12/30\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0799 - acc: 0.9750 - val_loss: 0.3737 - val_acc: 0.8660\n",
            "Epoch 13/30\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0671 - acc: 0.9803 - val_loss: 0.3899 - val_acc: 0.8612\n",
            "Epoch 14/30\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0560 - acc: 0.9853 - val_loss: 0.4036 - val_acc: 0.8622\n",
            "Epoch 15/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0460 - acc: 0.9884 - val_loss: 0.4150 - val_acc: 0.8612\n",
            "Epoch 16/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0373 - acc: 0.9913 - val_loss: 0.4367 - val_acc: 0.8596\n",
            "Epoch 17/30\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.0301 - acc: 0.9933 - val_loss: 0.4602 - val_acc: 0.8564\n",
            "Epoch 18/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0244 - acc: 0.9947 - val_loss: 0.4776 - val_acc: 0.8568\n",
            "Epoch 19/30\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0197 - acc: 0.9955 - val_loss: 0.4974 - val_acc: 0.8552\n",
            "Epoch 20/30\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0158 - acc: 0.9967 - val_loss: 0.5143 - val_acc: 0.8560\n",
            "Epoch 21/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0126 - acc: 0.9975 - val_loss: 0.5351 - val_acc: 0.8528\n",
            "Epoch 22/30\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.0099 - acc: 0.9981 - val_loss: 0.5555 - val_acc: 0.8538\n",
            "Epoch 23/30\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0081 - acc: 0.9984 - val_loss: 0.5809 - val_acc: 0.8542\n",
            "Epoch 24/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.5937 - val_acc: 0.8538\n",
            "Epoch 25/30\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0054 - acc: 0.9991 - val_loss: 0.6142 - val_acc: 0.8542\n",
            "Epoch 26/30\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0044 - acc: 0.9993 - val_loss: 0.6299 - val_acc: 0.8520\n",
            "Epoch 27/30\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.6435 - val_acc: 0.8536\n",
            "Epoch 28/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.6609 - val_acc: 0.8530\n",
            "Epoch 29/30\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 0.6722 - val_acc: 0.8528\n",
            "Epoch 30/30\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.6872 - val_acc: 0.8500\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"model1.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "\n",
        "# Model Fit - Running the Model\n",
        "Model_1 = model.fit(x_train, y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGxIcTBOe33J",
        "outputId": "95355a40-5d5d-4306-87c8-b8bbf11ae3a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3009 - acc: 0.8716\n",
            "Loss: 0.301\n",
            "Accuracy: 0.872\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('model1.keras')\n",
        "Model1_Results = test_model.evaluate(x_test,y_test)\n",
        "print(f'Loss: {Model1_Results[0]:.3f}')\n",
        "print(f'Accuracy: {Model1_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSb_3Usfx7bc"
      },
      "source": [
        "Without limiting the training, validaiton and test samples with a embedding layer the model resulted in 87.16% Accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXqyc5-DgRmk"
      },
      "source": [
        "### ***Model 2 Training Sample - 100, Validation Sample - 10000, Test Sample - 5000***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAZckObCmede"
      },
      "outputs": [],
      "source": [
        "# Setting the maximum number of words to be used in the vocabulary\n",
        "num_words = 10000\n",
        "\n",
        "# Loading the IMDB Dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "# Cut-Off the reviews after 150 words\n",
        "maxlen = 150\n",
        "train_data = pad_sequences(train_data, maxlen=maxlen)\n",
        "test_data = pad_sequences(test_data, maxlen=maxlen)\n",
        "\n",
        "# Combining the Training and Testing data create an entire dataset\n",
        "texts = np.concatenate((train_data, test_data), axis=0)\n",
        "labels = np.concatenate((train_labels, test_labels), axis=0)\n",
        "\n",
        "# Splitting the data into Training and Validation Samples\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, train_size=100, test_size=10000, random_state=42, stratify=labels)\n",
        "\n",
        "# Further split the data to get the test size of 5000 samples\n",
        "_, test_texts, _, test_labels = train_test_split(test_data, test_labels, test_size=5000, random_state=42, stratify=test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix5i8e-tPtw4"
      },
      "source": [
        "*Building the Network*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2riO_G_AKCNR"
      },
      "outputs": [],
      "source": [
        "# Setting the Sequential Layer for Model Building\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the Embedding Layer with limiting to consider only the top 10,000 Words\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "\n",
        "# Flattening the Size \n",
        "model.add(Flatten())\n",
        "\n",
        "# Adding the Classifer on the top - As the final layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the Model\n",
        "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxMMr2RhPwVd"
      },
      "source": [
        "*Summary of the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTsDTkK7KFeH",
        "outputId": "5e86e73a-88a5-43d5-a4ca-455d86f33579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 150, 8)            80000     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1201      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,201\n",
            "Trainable params: 81,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBPK3H-xPzT0"
      },
      "source": [
        "*Model Execution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzRezGP1KGpA",
        "outputId": "f102026a-a2ae-40ae-d9d2-bd7fde70be04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4/4 [==============================] - 6s 379ms/step - loss: 0.6966 - acc: 0.4000 - val_loss: 0.6926 - val_acc: 0.5151\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 1s 366ms/step - loss: 0.6746 - acc: 0.8200 - val_loss: 0.6926 - val_acc: 0.5139\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.6595 - acc: 0.9200 - val_loss: 0.6925 - val_acc: 0.5139\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 1s 372ms/step - loss: 0.6459 - acc: 0.9500 - val_loss: 0.6925 - val_acc: 0.5160\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.6330 - acc: 0.9600 - val_loss: 0.6923 - val_acc: 0.5146\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.6205 - acc: 0.9600 - val_loss: 0.6922 - val_acc: 0.5133\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 1s 363ms/step - loss: 0.6075 - acc: 0.9600 - val_loss: 0.6922 - val_acc: 0.5134\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 1s 343ms/step - loss: 0.5941 - acc: 0.9600 - val_loss: 0.6922 - val_acc: 0.5146\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 1s 405ms/step - loss: 0.5802 - acc: 0.9600 - val_loss: 0.6921 - val_acc: 0.5134\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 1s 375ms/step - loss: 0.5658 - acc: 0.9600 - val_loss: 0.6921 - val_acc: 0.5139\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 0.5513 - acc: 0.9700 - val_loss: 0.6921 - val_acc: 0.5131\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 1s 396ms/step - loss: 0.5360 - acc: 0.9800 - val_loss: 0.6921 - val_acc: 0.5127\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.5198 - acc: 0.9900 - val_loss: 0.6921 - val_acc: 0.5128\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.5035 - acc: 0.9900 - val_loss: 0.6921 - val_acc: 0.5142\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.4868 - acc: 0.9900 - val_loss: 0.6922 - val_acc: 0.5149\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.4695 - acc: 0.9900 - val_loss: 0.6922 - val_acc: 0.5151\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.4523 - acc: 0.9900 - val_loss: 0.6922 - val_acc: 0.5144\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.4347 - acc: 0.9900 - val_loss: 0.6923 - val_acc: 0.5150\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 1s 364ms/step - loss: 0.4174 - acc: 0.9900 - val_loss: 0.6923 - val_acc: 0.5156\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.4000 - acc: 0.9900 - val_loss: 0.6925 - val_acc: 0.5154\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.3827 - acc: 0.9900 - val_loss: 0.6926 - val_acc: 0.5161\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.3657 - acc: 0.9900 - val_loss: 0.6926 - val_acc: 0.5176\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.3485 - acc: 0.9900 - val_loss: 0.6927 - val_acc: 0.5194\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.3314 - acc: 0.9900 - val_loss: 0.6929 - val_acc: 0.5190\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.3145 - acc: 0.9900 - val_loss: 0.6931 - val_acc: 0.5202\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 1s 364ms/step - loss: 0.2983 - acc: 1.0000 - val_loss: 0.6931 - val_acc: 0.5178\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.2823 - acc: 1.0000 - val_loss: 0.6934 - val_acc: 0.5188\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 2s 636ms/step - loss: 0.2670 - acc: 1.0000 - val_loss: 0.6936 - val_acc: 0.5179\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 1s 385ms/step - loss: 0.2518 - acc: 1.0000 - val_loss: 0.6938 - val_acc: 0.5197\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.2374 - acc: 1.0000 - val_loss: 0.6940 - val_acc: 0.5197\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"model2.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "\n",
        "# Model Fit - Running the Model\n",
        "Model_2 = model.fit(train_texts, train_labels,\n",
        "                    epochs=30,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(val_texts, val_labels), \n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiVBRUzRNWeC",
        "outputId": "1519feff-93f1-49c1-89dc-ea5a144dde55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 3ms/step - loss: 0.6925 - acc: 0.5166\n",
            "Loss: 0.693\n",
            "Accuracy: 0.517\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('model2.keras')\n",
        "Model2_Results = test_model.evaluate(test_texts,test_labels)\n",
        "print(f'Loss: {Model2_Results[0]:.3f}')\n",
        "print(f'Accuracy: {Model2_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xL8o5HNygM1"
      },
      "source": [
        "The model with 100 training samples which was built with just an embedding layer resulted in 51.7% Accuracy, which is not that bad because the model was just trained with 100 Samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTSwX-KeY96M"
      },
      "source": [
        "### ***Model 3 Using Conv1d and Embedding Layer Together***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amqLFWs1eJ0a"
      },
      "source": [
        "*Training - 1000, Validation - 10000 and Test - 5000*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQM1FWtpY88v",
        "outputId": "cd2510d2-000f-4a4d-cde1-6c0922c52eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Setting the maximum number of words to be used in the vocabulary\n",
        "num_words = 10000\n",
        "\n",
        "# Loading the IMDB Dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "# Cut-Off the reviews after 150 words\n",
        "maxlen = 150\n",
        "train_data = pad_sequences(train_data, maxlen=maxlen)\n",
        "test_data = pad_sequences(test_data, maxlen=maxlen)\n",
        "\n",
        "# Combining the Training and Testing data create an entire dataset\n",
        "texts = np.concatenate((train_data, test_data), axis=0)\n",
        "labels = np.concatenate((train_labels, test_labels), axis=0)\n",
        "\n",
        "# Splitting the data into Training and Validation Samples\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, train_size=1000, test_size=10000, random_state=42, stratify=labels)\n",
        "\n",
        "# Further split the data to get the test size of 5000 samples\n",
        "_, test_texts, _, test_labels = train_test_split(test_data, test_labels, test_size=5000, random_state=42, stratify=test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D_2EBXVebxD"
      },
      "source": [
        "*Building the Network - Conv1D along with the Embedding*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szvrKHqNZdlR"
      },
      "outputs": [],
      "source": [
        "# Setting the Sequential Layer for Model Building\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the Embedding Layer with limiting to consider only the top 10,000 Words\n",
        "maxlen = 150\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "\n",
        "model.add(Conv1D(512, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "\n",
        "model.add(Conv1D(256, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "\n",
        "model.add(Conv1D(256, 3, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "model.add(MaxPooling1D(3))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Compiling the Model\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaXtLVwoek_P"
      },
      "source": [
        "*Summary of the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Yn1KUvZdi5",
        "outputId": "e82786ac-20ba-45d6-9df7-1cd68a4ab879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 150, 8)            80000     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 148, 512)          12800     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 49, 512)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 47, 256)           393472    \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 15, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 13, 256)           196864    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 749,185\n",
            "Trainable params: 749,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNDg8njJetdm"
      },
      "source": [
        "*Running the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaNBFG7DZdgG",
        "outputId": "d6cc702a-2ca4-426e-9bf8-5b93f73aab00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "32/32 [==============================] - 20s 285ms/step - loss: 0.6945 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5289\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 0.6933 - accuracy: 0.5120 - val_loss: 0.6931 - val_accuracy: 0.5055\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 6s 202ms/step - loss: 0.6928 - accuracy: 0.5120 - val_loss: 0.6930 - val_accuracy: 0.5123\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 5s 177ms/step - loss: 0.6927 - accuracy: 0.5140 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.6922 - accuracy: 0.5240 - val_loss: 0.6929 - val_accuracy: 0.5202\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 5s 146ms/step - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.6926 - accuracy: 0.4960 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 4s 134ms/step - loss: 0.6897 - accuracy: 0.5320 - val_loss: 0.6924 - val_accuracy: 0.5616\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 2s 79ms/step - loss: 0.6858 - accuracy: 0.5740 - val_loss: 0.6919 - val_accuracy: 0.5011\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 3s 81ms/step - loss: 0.6765 - accuracy: 0.6020 - val_loss: 0.6894 - val_accuracy: 0.5482\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 2s 80ms/step - loss: 0.6467 - accuracy: 0.6730 - val_loss: 0.6823 - val_accuracy: 0.5923\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.5587 - accuracy: 0.7660 - val_loss: 0.6579 - val_accuracy: 0.6844\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 3s 83ms/step - loss: 0.4228 - accuracy: 0.8250 - val_loss: 0.6293 - val_accuracy: 0.6799\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 3s 102ms/step - loss: 0.2701 - accuracy: 0.9100 - val_loss: 0.5987 - val_accuracy: 0.7081\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.1926 - accuracy: 0.9370 - val_loss: 0.5835 - val_accuracy: 0.7087\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.1604 - accuracy: 0.9390 - val_loss: 0.5653 - val_accuracy: 0.7278\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0788 - accuracy: 0.9770 - val_loss: 0.5568 - val_accuracy: 0.7288\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.0580 - accuracy: 0.9860 - val_loss: 0.5587 - val_accuracy: 0.7194\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.5502 - val_accuracy: 0.7283\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 3s 105ms/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.5442 - val_accuracy: 0.7279\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0189 - accuracy: 0.9970 - val_loss: 0.5420 - val_accuracy: 0.7285\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.0126 - accuracy: 0.9990 - val_loss: 0.5461 - val_accuracy: 0.7269\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 2s 52ms/step - loss: 0.0099 - accuracy: 0.9990 - val_loss: 0.5475 - val_accuracy: 0.7251\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 2s 52ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.5447 - val_accuracy: 0.7274\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.5431 - val_accuracy: 0.7278\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.5418 - val_accuracy: 0.7288\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.7282\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 2s 67ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.7257\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 2s 54ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.5535 - val_accuracy: 0.7254\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 2s 52ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.7290\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"model3.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "\n",
        "# Model Fit - Running the Model\n",
        "Model_3 = model.fit(train_texts, train_labels,\n",
        "                    epochs=30,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(val_texts, val_labels), \n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThrC1WnbZdSf",
        "outputId": "063c4a58-76ac-40db-9956-fb60aad3b9e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.7436\n",
            "Loss: 0.524\n",
            "Accuracy: 0.744\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('model3.keras')\n",
        "Model3_Results = test_model.evaluate(test_texts,test_labels)\n",
        "print(f'Loss: {Model3_Results[0]:.3f}')\n",
        "print(f'Accuracy: {Model3_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e5fk-R3y5TT"
      },
      "source": [
        "This is interesting to observe as soon as we increase the training sample size to 1000 and by building a complex network i.e. using Conv1D along with Embedding actually resulted in 74.4% Accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JS5eMhiijJE"
      },
      "source": [
        "### ***Model 4 Conv1D and Embedding Layer Together With Change in Network***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLdoUF8YpsEQ"
      },
      "source": [
        "*Training - 25000, Validation - 10000 and Test - 5000*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMGKGNyrijzw"
      },
      "outputs": [],
      "source": [
        "# Setting the maximum number of words to be used in the vocabulary\n",
        "num_words = 10000\n",
        "\n",
        "# Loading the IMDB Dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "# Cut-Off the reviews after 150 words\n",
        "maxlen = 150\n",
        "train_data = pad_sequences(train_data, maxlen=maxlen)\n",
        "test_data = pad_sequences(test_data, maxlen=maxlen)\n",
        "\n",
        "# Combining the Training and Testing data create an entire dataset\n",
        "texts = np.concatenate((train_data, test_data), axis=0)\n",
        "labels = np.concatenate((train_labels, test_labels), axis=0)\n",
        "\n",
        "# Splitting the data into Training and Validation Samples\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, train_size=25000, test_size=10000, random_state=42, stratify=labels)\n",
        "\n",
        "# Further split the data to get the test size of 5000 samples\n",
        "_, test_texts, _, test_labels = train_test_split(test_data, test_labels, test_size=5000, random_state=42, stratify=test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av1w7whIosIz"
      },
      "source": [
        "*We are adding a additional layer to both the Conv1d as well as the Dense network at the end, we also changed the embedding vector dimension to 12 and added dropout layers to all the input layers so as to avoid overfitting*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SN0bpFXjAkc"
      },
      "outputs": [],
      "source": [
        "# Setting the Sequential Layer for Model Building\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the Embedding Layer with limiting to consider only the top 10,000 Words\n",
        "maxlen = 150\n",
        "model.add(Embedding(10000, 12, input_length=maxlen))\n",
        "\n",
        "model.add(Conv1D(512, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(Conv1D(256, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(Conv1D(256, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Compiling the Model\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0002)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN8Lu1O2o-PV"
      },
      "source": [
        "*Summary of the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JCTpQWVjt2P",
        "outputId": "fccf3404-1c29-41ac-a6ae-6faf24d90fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 150, 12)           120000    \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 148, 512)          18944     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 148, 512)          0         \n",
            "                                                                 \n",
            " max_pooling1d_11 (MaxPoolin  (None, 74, 512)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 72, 256)           393472    \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 72, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 36, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 34, 256)           196864    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 34, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 17, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_14 (Conv1D)          (None, 15, 128)           98432     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 15, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPoolin  (None, 7, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               66048     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,156,929\n",
            "Trainable params: 1,156,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRhwTbzFpCQ7"
      },
      "source": [
        "*Running the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7v0-1wwk5Eb",
        "outputId": "13cf1d76-8637-4311-f18c-858cec012c09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 54s 128ms/step - loss: 0.6935 - accuracy: 0.5046 - val_loss: 0.6930 - val_accuracy: 0.5175\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 0.6119 - accuracy: 0.6204 - val_loss: 0.5585 - val_accuracy: 0.7876\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3548 - accuracy: 0.8487 - val_loss: 0.4926 - val_accuracy: 0.8456\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.2808 - accuracy: 0.8878 - val_loss: 0.4517 - val_accuracy: 0.8455\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 8s 22ms/step - loss: 0.2400 - accuracy: 0.9035 - val_loss: 0.4427 - val_accuracy: 0.8443\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 0.2126 - accuracy: 0.9191 - val_loss: 0.4206 - val_accuracy: 0.8450\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1838 - accuracy: 0.9310 - val_loss: 0.4080 - val_accuracy: 0.8351\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 0.1586 - accuracy: 0.9429 - val_loss: 0.3911 - val_accuracy: 0.8380\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.1412 - accuracy: 0.9500 - val_loss: 0.3914 - val_accuracy: 0.8332\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1212 - accuracy: 0.9565 - val_loss: 0.3852 - val_accuracy: 0.8317\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1003 - accuracy: 0.9669 - val_loss: 0.3994 - val_accuracy: 0.8236\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0879 - accuracy: 0.9702 - val_loss: 0.4071 - val_accuracy: 0.8249\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.0792 - accuracy: 0.9745 - val_loss: 0.4271 - val_accuracy: 0.8158\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.4262 - val_accuracy: 0.8216\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0561 - accuracy: 0.9822 - val_loss: 0.4542 - val_accuracy: 0.8152\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.4759 - val_accuracy: 0.8140\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0492 - accuracy: 0.9837 - val_loss: 0.4459 - val_accuracy: 0.8104\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.4886 - val_accuracy: 0.8096\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 0.5071 - val_accuracy: 0.8093\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.5001 - val_accuracy: 0.8124\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.5493 - val_accuracy: 0.8142\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.5365 - val_accuracy: 0.8122\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.6026 - val_accuracy: 0.8014\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 0.5203 - val_accuracy: 0.8104\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.6074 - val_accuracy: 0.8081\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.6620 - val_accuracy: 0.8090\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.6404 - val_accuracy: 0.8089\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.6042 - val_accuracy: 0.8074\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.6698 - val_accuracy: 0.8108\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.6881 - val_accuracy: 0.8124\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.7322 - val_accuracy: 0.8066\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.6891 - val_accuracy: 0.8055\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.6335 - val_accuracy: 0.8062\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.8493 - val_accuracy: 0.8001\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.7308 - val_accuracy: 0.8068\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0163 - accuracy: 0.9941 - val_loss: 0.7812 - val_accuracy: 0.8096\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.8451 - val_accuracy: 0.7999\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.8453 - val_accuracy: 0.8058\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.8401 - val_accuracy: 0.8078\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.8090 - val_accuracy: 0.8057\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.0182 - val_accuracy: 0.8057\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.0638 - val_accuracy: 0.8018\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.8921 - val_accuracy: 0.8090\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.7405 - val_accuracy: 0.8074\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.9637 - val_accuracy: 0.8032\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 1.0171 - val_accuracy: 0.8027\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 1.0114 - val_accuracy: 0.8057\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.8538 - val_accuracy: 0.8092\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 1.0631 - val_accuracy: 0.8077\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 1.0671 - val_accuracy: 0.8081\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"model4.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "\n",
        "# Model Fit - Running the Model\n",
        "Model_4 = model.fit(train_texts, train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(val_texts, val_labels), \n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn-0egnTpKIj"
      },
      "source": [
        "*Model Evaluation - Test Set*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkBsRWx8lGbi",
        "outputId": "6a697572-248b-4688-8010-b0088793aa6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 7ms/step - loss: 0.2899 - accuracy: 0.9080\n",
            "Loss: 0.290\n",
            "Accuracy: 0.908\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('model4.keras')\n",
        "Model4_Results = test_model.evaluate(test_texts,test_labels)\n",
        "print(f'Loss: {Model4_Results[0]:.3f}')\n",
        "print(f'Accuracy: {Model4_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhMr4xfgzTVq"
      },
      "source": [
        "We built a much more complex network i.e. increased the input layers of the Conv1D and also added Dropout for each layer to avoid overfitting, lastly we added 2 dense layers again with dropout and the optimizer being Adam with 0.0002 learning rate, this network along with training samples of 25000 resulted in 90.8% Accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlaToBWIv5Ul"
      },
      "source": [
        "### ***Model 5 Conv1D and Embedding Layer with Change in Embedding Vector***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG9vwCbzwAUO"
      },
      "source": [
        "*Training - 35000, Validation - 10000 and Test - 5000*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MFtWn14rzDo"
      },
      "outputs": [],
      "source": [
        "# Setting the maximum number of words to be used in the vocabulary\n",
        "num_words = 10000\n",
        "\n",
        "# Loading the IMDB Dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "# Cut-Off the reviews after 150 words\n",
        "maxlen = 150\n",
        "train_data = pad_sequences(train_data, maxlen=maxlen)\n",
        "test_data = pad_sequences(test_data, maxlen=maxlen)\n",
        "\n",
        "# Combining the Training and Testing data create an entire dataset\n",
        "texts = np.concatenate((train_data, test_data), axis=0)\n",
        "labels = np.concatenate((train_labels, test_labels), axis=0)\n",
        "\n",
        "# Splitting the data into Training and Validation Samples\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, train_size=35000, test_size=10000, random_state=42, stratify=labels)\n",
        "\n",
        "# Further split the data to get the test size of 5000 samples\n",
        "_, test_texts, _, test_labels = train_test_split(test_data, test_labels, test_size=5000, random_state=42, stratify=test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJftcMJUv0CT"
      },
      "source": [
        "*Verifying the sizes of training, validation and test datasets*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnGP-VfyswVc",
        "outputId": "eca7a8b4-d75d-46a7-e578-f4a16a10d2b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35000, 150)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_texts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpfK6Jtysx0S",
        "outputId": "a72d22cb-5301-4bb2-ff93-3ebb88230165"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 150)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_texts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AkFLblHszOn",
        "outputId": "0684c544-c501-4051-9c88-75f3ca591f47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 150)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_texts.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT9L54osvn9Y"
      },
      "source": [
        "*Building the Network*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJbCtsWLryqo"
      },
      "outputs": [],
      "source": [
        "# Setting the Sequential Layer for Model Building\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the Embedding Layer with limiting to consider only the top 10,000 Words\n",
        "maxlen = 150\n",
        "model.add(Embedding(10000, 14, input_length=maxlen))\n",
        "\n",
        "model.add(Conv1D(512, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(Conv1D(256, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(Conv1D(256, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Compiling the Model\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0002)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdAnmRQuvlce"
      },
      "source": [
        "*Summary of the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnL9yzrRsQtP",
        "outputId": "fecbb382-f291-437c-ef62-af9a34a1c0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 150, 14)           140000    \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 148, 512)          22016     \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 148, 512)          0         \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 74, 512)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_16 (Conv1D)          (None, 72, 256)           393472    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 72, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d_16 (MaxPoolin  (None, 36, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 34, 256)           196864    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 34, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 17, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, 15, 128)           98432     \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 15, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 7, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               66048     \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,180,001\n",
            "Trainable params: 1,180,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjA5suWtvjYr"
      },
      "source": [
        "*Running the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT1bd3pesQhQ",
        "outputId": "ac13fdc3-3a36-4040-dae4-e6759f018767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "547/547 [==============================] - 67s 117ms/step - loss: 0.6829 - accuracy: 0.5293 - val_loss: 0.6141 - val_accuracy: 0.7312\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - 14s 26ms/step - loss: 0.3903 - accuracy: 0.8272 - val_loss: 0.4930 - val_accuracy: 0.8428\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - 12s 22ms/step - loss: 0.2991 - accuracy: 0.8768 - val_loss: 0.4477 - val_accuracy: 0.8498\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - 12s 22ms/step - loss: 0.2622 - accuracy: 0.8940 - val_loss: 0.4368 - val_accuracy: 0.8509\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 0.2339 - accuracy: 0.9086 - val_loss: 0.4203 - val_accuracy: 0.8503\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - 12s 22ms/step - loss: 0.2122 - accuracy: 0.9175 - val_loss: 0.4045 - val_accuracy: 0.8439\n",
            "Epoch 7/50\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 0.1929 - accuracy: 0.9254 - val_loss: 0.3944 - val_accuracy: 0.8394\n",
            "Epoch 8/50\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 0.1732 - accuracy: 0.9353 - val_loss: 0.3847 - val_accuracy: 0.8352\n",
            "Epoch 9/50\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 0.1588 - accuracy: 0.9415 - val_loss: 0.3906 - val_accuracy: 0.8314\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.1353 - accuracy: 0.9509 - val_loss: 0.3794 - val_accuracy: 0.8372\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - 10s 17ms/step - loss: 0.1204 - accuracy: 0.9572 - val_loss: 0.3882 - val_accuracy: 0.8289\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - 10s 17ms/step - loss: 0.1105 - accuracy: 0.9622 - val_loss: 0.3929 - val_accuracy: 0.8301\n",
            "Epoch 13/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0926 - accuracy: 0.9679 - val_loss: 0.4051 - val_accuracy: 0.8279\n",
            "Epoch 14/50\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 0.0792 - accuracy: 0.9737 - val_loss: 0.4170 - val_accuracy: 0.8301\n",
            "Epoch 15/50\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 0.0719 - accuracy: 0.9756 - val_loss: 0.4430 - val_accuracy: 0.8248\n",
            "Epoch 16/50\n",
            "547/547 [==============================] - 10s 17ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 0.4573 - val_accuracy: 0.8245\n",
            "Epoch 17/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.4811 - val_accuracy: 0.8253\n",
            "Epoch 18/50\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.5019 - val_accuracy: 0.8233\n",
            "Epoch 19/50\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 0.4622 - val_accuracy: 0.8241\n",
            "Epoch 20/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.4971 - val_accuracy: 0.8249\n",
            "Epoch 21/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0399 - accuracy: 0.9867 - val_loss: 0.5372 - val_accuracy: 0.8201\n",
            "Epoch 22/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.5429 - val_accuracy: 0.8222\n",
            "Epoch 23/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.5735 - val_accuracy: 0.8206\n",
            "Epoch 24/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0306 - accuracy: 0.9898 - val_loss: 0.5698 - val_accuracy: 0.8231\n",
            "Epoch 25/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 0.6073 - val_accuracy: 0.8228\n",
            "Epoch 26/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.6278 - val_accuracy: 0.8224\n",
            "Epoch 27/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.6411 - val_accuracy: 0.8213\n",
            "Epoch 28/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.7142 - val_accuracy: 0.8221\n",
            "Epoch 29/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.6411 - val_accuracy: 0.8170\n",
            "Epoch 30/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.6909 - val_accuracy: 0.8140\n",
            "Epoch 31/50\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.7162 - val_accuracy: 0.8141\n",
            "Epoch 32/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.7193 - val_accuracy: 0.8196\n",
            "Epoch 33/50\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.8123 - val_accuracy: 0.8198\n",
            "Epoch 34/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.7174 - val_accuracy: 0.8189\n",
            "Epoch 35/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.6537 - val_accuracy: 0.8199\n",
            "Epoch 36/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.7302 - val_accuracy: 0.8221\n",
            "Epoch 37/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.7829 - val_accuracy: 0.8205\n",
            "Epoch 38/50\n",
            "547/547 [==============================] - 11s 19ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.8036 - val_accuracy: 0.8188\n",
            "Epoch 39/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.8303 - val_accuracy: 0.8194\n",
            "Epoch 40/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.8315 - val_accuracy: 0.8200\n",
            "Epoch 41/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.8178 - val_accuracy: 0.8176\n",
            "Epoch 42/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.8411 - val_accuracy: 0.8163\n",
            "Epoch 43/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.7921 - val_accuracy: 0.8180\n",
            "Epoch 44/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.0256 - val_accuracy: 0.8185\n",
            "Epoch 45/50\n",
            "547/547 [==============================] - 9s 16ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.8147 - val_accuracy: 0.8155\n",
            "Epoch 46/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.8400 - val_accuracy: 0.8170\n",
            "Epoch 47/50\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 1.0151 - val_accuracy: 0.8152\n",
            "Epoch 48/50\n",
            "547/547 [==============================] - 9s 17ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.7309 - val_accuracy: 0.8182\n",
            "Epoch 49/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.8863 - val_accuracy: 0.8165\n",
            "Epoch 50/50\n",
            "547/547 [==============================] - 8s 15ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 1.0670 - val_accuracy: 0.8161\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"model5.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "\n",
        "# Model Fit - Running the Model\n",
        "Model_5 = model.fit(train_texts, train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(val_texts, val_labels), \n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfPIkyMBvala"
      },
      "source": [
        "*Visualizing the Training and Validation Loss/Accuracy*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fefsP_7Rve81"
      },
      "source": [
        "*Evaluating the Model on Test Set*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qykQqdTfsQD2",
        "outputId": "b16bbfda-6a5d-4746-b1bf-34a8308ebac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.9256\n",
            "Loss: 0.257\n",
            "Accuracy: 0.926\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('model5.keras')\n",
        "Model5_Results = test_model.evaluate(test_texts,test_labels)\n",
        "print(f'Loss: {Model5_Results[0]:.3f}')\n",
        "print(f'Accuracy: {Model5_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtA0jDclwOmS"
      },
      "source": [
        "Just by changing the embedding vector dimension from 12 to 14 and having 10000+ samples for the training when compared to the previous model, model 5 deemed to be the best with highest accuracy of 92.6%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZyH7AEpwgf3"
      },
      "source": [
        "***We can thus consider the embedding vector dimension as a key hyper parameter to play around with while building the network, but it should be noted that if this parameter is set very high then the model may start to overfit and vice-versa. So, the value thus chosen should be based on the size of the dataset and the end-optimization goal.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtoxcFauIR_c"
      },
      "source": [
        "It's not just the embedding vector dimension which is a key hyper parameter we can also fine tune the learning rate, dropout rate, add more or reduce input conv1d layers and dense layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3v8HSoLw6_4"
      },
      "source": [
        "We built 4 models in the embedding part i.e. Model 2, Model 3, Model 4 and Model 5. Model 1 was just an base model we aren't considering it for the best model evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41k0Ak4gxH_J"
      },
      "source": [
        "### ***Evaluating the Best Model - Embedding Base Models***"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GXcTpJ-60rSc"
      },
      "source": [
        "*The reported accuracy was achieved using a training sample size of 35,000, validation size of 10,000, and test size of 5,000. The model architecture utilized both Conv1D and Embedding layers, and the specific network structure can be viewed by examining the model summary.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWNs0p9OxahV"
      },
      "source": [
        "## ***Pre-Trained Models***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqa-ZjF5T51q"
      },
      "source": [
        "### ***Pretrained Word Embedding Model GloVe***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eomP_BeP0rdf"
      },
      "source": [
        "### ***PreTrained Model 1 with Training Samples of 1000***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB55PCou00gq"
      },
      "source": [
        "Loading in the IMDB .tar file to the colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-BcF3H-QcDH",
        "outputId": "05056db9-dac4-4999-d3a7-2cc6475f20b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  48.9M      0  0:00:01  0:00:01 --:--:-- 48.9M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU65b6HURcyV"
      },
      "outputs": [],
      "source": [
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQVQlpEF1BIt"
      },
      "source": [
        "Creating Directories and Appending the data further from Neg and Pos Class of the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF48OQwkwGP4"
      },
      "outputs": [],
      "source": [
        "imdb_dir = '/content/aclImdb'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD1fJAVd1Jpf"
      },
      "source": [
        "Looking at the total samples in the train class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBWetgEjKq7V",
        "outputId": "d2c2422f-0091-46e9-afb8-86ab6da93130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of Samples 25000\n"
          ]
        }
      ],
      "source": [
        "print('No. of Samples', len(texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7UI-NCE1Oz6"
      },
      "source": [
        "Getting the data ready for modelling and creating train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOH4kKK3uq9B",
        "outputId": "a8eb148d-7b83-4b6f-a5eb-852c9bd1335e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 150)\n",
            "Shape of label tensor: (25000,)\n"
          ]
        }
      ],
      "source": [
        "maxlen = 150  # cutting off reviews after 150 words\n",
        "training_samples = 100  # training on 100 samples\n",
        "validation_samples = 10000  # validating on 10000 samples\n",
        "max_words = 10000  # considering the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Splitting the data into a training set and a validation set\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRfjUOS_3k3w",
        "outputId": "656af0d7-c087-485b-e7fb-f082664e54c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fXsKkHT1rXi"
      },
      "source": [
        "Loading the pre-trained word embedding file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqMtKVpeIxRu",
        "outputId": "09bf8172-b529-43a3-f196-9046ea33084e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "glove_dir = '/content/gdrive/My Drive/glove'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB7ErTj611W2"
      },
      "source": [
        "Creating a embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPJUbgOOI90W"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVO0ER_VTxu6"
      },
      "source": [
        "*Building the Network*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxeL1_ysTIu8"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "# Compiling the Model\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD0kwcloTrS7"
      },
      "source": [
        "*Summary of the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMj6UoA2TNWh",
        "outputId": "d4d5aca0-fae8-4563-b9d4-b44884c011dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 150, 100)          1000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                17024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,017,057\n",
            "Trainable params: 17,057\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6CQLLFTtVp"
      },
      "source": [
        "*Running the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q4hqvknTN2l",
        "outputId": "4ecceb9a-d571-4181-ce75-8e5a24cfd721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4/4 [==============================] - 14s 4s/step - loss: 0.7047 - accuracy: 0.4800 - val_loss: 0.7054 - val_accuracy: 0.5074\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.7000 - accuracy: 0.4900 - val_loss: 0.7037 - val_accuracy: 0.5083\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6971 - accuracy: 0.5100 - val_loss: 0.7023 - val_accuracy: 0.5084\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6944 - accuracy: 0.5100 - val_loss: 0.7009 - val_accuracy: 0.5077\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6997 - val_accuracy: 0.5089\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 11s 4s/step - loss: 0.6897 - accuracy: 0.4900 - val_loss: 0.6982 - val_accuracy: 0.5077\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6868 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.5098\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6845 - accuracy: 0.5300 - val_loss: 0.6965 - val_accuracy: 0.5111\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6830 - accuracy: 0.5400 - val_loss: 0.6960 - val_accuracy: 0.5109\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6819 - accuracy: 0.5500 - val_loss: 0.6954 - val_accuracy: 0.5119\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6797 - accuracy: 0.5500 - val_loss: 0.6950 - val_accuracy: 0.5127\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6782 - accuracy: 0.5500 - val_loss: 0.6944 - val_accuracy: 0.5133\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6764 - accuracy: 0.5700 - val_loss: 0.6939 - val_accuracy: 0.5135\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.6748 - accuracy: 0.5600 - val_loss: 0.6934 - val_accuracy: 0.5149\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6729 - accuracy: 0.5700 - val_loss: 0.6930 - val_accuracy: 0.5187\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6715 - accuracy: 0.5700 - val_loss: 0.6926 - val_accuracy: 0.5179\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6697 - accuracy: 0.6000 - val_loss: 0.6924 - val_accuracy: 0.5220\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 11s 4s/step - loss: 0.6686 - accuracy: 0.6300 - val_loss: 0.6923 - val_accuracy: 0.5234\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6671 - accuracy: 0.6400 - val_loss: 0.6922 - val_accuracy: 0.5242\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6659 - accuracy: 0.6400 - val_loss: 0.6921 - val_accuracy: 0.5251\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6650 - accuracy: 0.6500 - val_loss: 0.6920 - val_accuracy: 0.5273\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6641 - accuracy: 0.6700 - val_loss: 0.6920 - val_accuracy: 0.5266\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.6627 - accuracy: 0.6500 - val_loss: 0.6920 - val_accuracy: 0.5254\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6622 - accuracy: 0.6500 - val_loss: 0.6920 - val_accuracy: 0.5258\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6607 - accuracy: 0.6600 - val_loss: 0.6919 - val_accuracy: 0.5266\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6595 - accuracy: 0.6600 - val_loss: 0.6918 - val_accuracy: 0.5286\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6595 - accuracy: 0.6600 - val_loss: 0.6916 - val_accuracy: 0.5306\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6581 - accuracy: 0.6500 - val_loss: 0.6916 - val_accuracy: 0.5329\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6573 - accuracy: 0.6500 - val_loss: 0.6915 - val_accuracy: 0.5327\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.6563 - accuracy: 0.6500 - val_loss: 0.6914 - val_accuracy: 0.5330\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks=callbacks = ModelCheckpoint(\n",
        "            filepath= \"premodel1.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "# Model Fit\n",
        "Pre_Model_1 =  model.fit(x_train, y_train, \n",
        "                     epochs=30, \n",
        "                     batch_size=32, \n",
        "                     validation_data=(x_val, y_val),\n",
        "                     callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3rhDBoV2ey5"
      },
      "source": [
        "Visualizing the Training and Validation Loss/Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh4loqx72jvE"
      },
      "source": [
        "Loading the test data for model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLM1zIjLVSml"
      },
      "outputs": [],
      "source": [
        "test_dir = os.path.join(imdb_dir, 'test')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(test_dir, label_type)\n",
        "    for fname in sorted(os.listdir(dir_name)):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)[:5000]\n",
        "y_test = np.asarray(labels)[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxMC-8l72rrI"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CNmHXx-WfXx",
        "outputId": "91cf7c1f-b8f5-4895-d1af-c932606c37d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 4s 25ms/step - loss: 0.6986 - accuracy: 0.4516\n",
            "Loss: 0.699\n",
            "Accuracy: 0.452\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('premodel1.keras')\n",
        "PreModel1_Results = test_model.evaluate(x_test,y_test)\n",
        "print(f'Loss: {PreModel1_Results[0]:.3f}')\n",
        "print(f'Accuracy: {PreModel1_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sKEoTlF2tLO"
      },
      "source": [
        "With 100 Training Samples the model thus built using the weights of the pre-trained model resulted in poor accuracy i.e. of 45.2%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE-ZK-DC27b-"
      },
      "source": [
        "### ***PreTrained Model 2 with Training Samples of 1000***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUR4-5gP27uM",
        "outputId": "91290e9b-94df-4220-f302-23d37b8d1b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 150)\n",
            "Shape of label tensor: (25000,)\n"
          ]
        }
      ],
      "source": [
        "maxlen = 150  # cutting off reviews after 150 words\n",
        "training_samples = 1000  # training on 1000 samples\n",
        "validation_samples = 10000  # validating on 10000 samples\n",
        "max_words = 10000  # considering the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Splitting the data into a training set and a validation set\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m-LXvFC6PFl"
      },
      "source": [
        "Verifying the size of the train and validation samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDi5vbvH6J7Z",
        "outputId": "7b5f1db3-be25-48c2-fe54-fd104456218b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 150)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jHvA1ch6L32",
        "outputId": "7d8eccb7-02b6-4ba4-ce46-970b7caaaa0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 150)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVJXfhKv5fLe"
      },
      "source": [
        "Building the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGeWajtB6ajM"
      },
      "source": [
        "Compared to the previous model the network architecture thus built is very strong by having more input layers and dropout and dense layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16v8gndy3Vya"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(LSTM(128))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "\n",
        "# Compiling the Model\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cUBmvI_6F52"
      },
      "source": [
        "Summary of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y7EUlTu6ICT",
        "outputId": "4f5aed1c-e648-4613-d0b4-a42807c3a8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 150, 100)          1000000   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 150, 512)          1255424   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 150, 512)          0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 150, 256)          787456    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 150, 256)          0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 150, 128)          197120    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 150, 128)          0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,470,657\n",
            "Trainable params: 2,470,657\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx61h8976wLh"
      },
      "source": [
        "Running the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUv8fax96xLD",
        "outputId": "47f3a5e1-b99b-4a7b-f312-78a877cf1dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "32/32 [==============================] - 23s 286ms/step - loss: 0.6908 - accuracy: 0.5290 - val_loss: 0.6925 - val_accuracy: 0.5069\n",
            "Epoch 2/40\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.6979 - accuracy: 0.4870 - val_loss: 0.6910 - val_accuracy: 0.5687\n",
            "Epoch 3/40\n",
            "32/32 [==============================] - 12s 374ms/step - loss: 0.6967 - accuracy: 0.4970 - val_loss: 0.6897 - val_accuracy: 0.5484\n",
            "Epoch 4/40\n",
            "32/32 [==============================] - 12s 379ms/step - loss: 0.6881 - accuracy: 0.5360 - val_loss: 0.6781 - val_accuracy: 0.6149\n",
            "Epoch 5/40\n",
            "32/32 [==============================] - 7s 221ms/step - loss: 0.6856 - accuracy: 0.5760 - val_loss: 0.6957 - val_accuracy: 0.4942\n",
            "Epoch 6/40\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 0.6983 - accuracy: 0.5050 - val_loss: 0.6867 - val_accuracy: 0.5646\n",
            "Epoch 7/40\n",
            "32/32 [==============================] - 12s 376ms/step - loss: 0.6773 - accuracy: 0.5720 - val_loss: 0.6613 - val_accuracy: 0.6027\n",
            "Epoch 8/40\n",
            "32/32 [==============================] - 12s 379ms/step - loss: 0.6465 - accuracy: 0.6430 - val_loss: 0.6181 - val_accuracy: 0.6639\n",
            "Epoch 9/40\n",
            "32/32 [==============================] - 7s 221ms/step - loss: 0.6275 - accuracy: 0.6630 - val_loss: 0.5811 - val_accuracy: 0.7148\n",
            "Epoch 10/40\n",
            "32/32 [==============================] - 12s 375ms/step - loss: 0.6753 - accuracy: 0.6300 - val_loss: 0.6467 - val_accuracy: 0.6706\n",
            "Epoch 11/40\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.6176 - accuracy: 0.7040 - val_loss: 0.5963 - val_accuracy: 0.6967\n",
            "Epoch 12/40\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 0.6108 - accuracy: 0.6820 - val_loss: 0.6312 - val_accuracy: 0.6590\n",
            "Epoch 13/40\n",
            "32/32 [==============================] - 12s 377ms/step - loss: 0.5835 - accuracy: 0.7090 - val_loss: 0.5454 - val_accuracy: 0.7329\n",
            "Epoch 14/40\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5561 - accuracy: 0.7330 - val_loss: 0.5661 - val_accuracy: 0.7076\n",
            "Epoch 15/40\n",
            "32/32 [==============================] - 12s 375ms/step - loss: 0.5794 - accuracy: 0.7120 - val_loss: 0.5948 - val_accuracy: 0.7200\n",
            "Epoch 16/40\n",
            "32/32 [==============================] - 12s 386ms/step - loss: 0.5341 - accuracy: 0.7560 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
            "Epoch 17/40\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.5684 - accuracy: 0.7290 - val_loss: 0.5352 - val_accuracy: 0.7463\n",
            "Epoch 18/40\n",
            "32/32 [==============================] - 12s 377ms/step - loss: 0.5554 - accuracy: 0.7340 - val_loss: 0.5144 - val_accuracy: 0.7529\n",
            "Epoch 19/40\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5080 - accuracy: 0.7780 - val_loss: 0.5134 - val_accuracy: 0.7525\n",
            "Epoch 20/40\n",
            "32/32 [==============================] - 12s 378ms/step - loss: 0.4986 - accuracy: 0.7770 - val_loss: 0.5291 - val_accuracy: 0.7418\n",
            "Epoch 21/40\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.4686 - accuracy: 0.7910 - val_loss: 0.5180 - val_accuracy: 0.7602\n",
            "Epoch 22/40\n",
            "32/32 [==============================] - 12s 378ms/step - loss: 0.4606 - accuracy: 0.7970 - val_loss: 0.5209 - val_accuracy: 0.7510\n",
            "Epoch 23/40\n",
            "32/32 [==============================] - 12s 377ms/step - loss: 0.4616 - accuracy: 0.8000 - val_loss: 0.5760 - val_accuracy: 0.7457\n",
            "Epoch 24/40\n",
            "32/32 [==============================] - 7s 218ms/step - loss: 0.4432 - accuracy: 0.8220 - val_loss: 0.5939 - val_accuracy: 0.7247\n",
            "Epoch 25/40\n",
            "32/32 [==============================] - 7s 221ms/step - loss: 0.5044 - accuracy: 0.7600 - val_loss: 0.5348 - val_accuracy: 0.7470\n",
            "Epoch 26/40\n",
            "32/32 [==============================] - 12s 373ms/step - loss: 0.4602 - accuracy: 0.7990 - val_loss: 0.5528 - val_accuracy: 0.7207\n",
            "Epoch 27/40\n",
            "32/32 [==============================] - 12s 376ms/step - loss: 0.4509 - accuracy: 0.8160 - val_loss: 0.5150 - val_accuracy: 0.7572\n",
            "Epoch 28/40\n",
            "32/32 [==============================] - 7s 221ms/step - loss: 0.4101 - accuracy: 0.8320 - val_loss: 0.6077 - val_accuracy: 0.7374\n",
            "Epoch 29/40\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 0.4356 - accuracy: 0.8200 - val_loss: 0.5517 - val_accuracy: 0.7567\n",
            "Epoch 30/40\n",
            "32/32 [==============================] - 12s 375ms/step - loss: 0.4345 - accuracy: 0.8160 - val_loss: 0.5235 - val_accuracy: 0.7480\n",
            "Epoch 31/40\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.3892 - accuracy: 0.8460 - val_loss: 0.6697 - val_accuracy: 0.7198\n",
            "Epoch 32/40\n",
            "32/32 [==============================] - 12s 373ms/step - loss: 0.4754 - accuracy: 0.7890 - val_loss: 0.6047 - val_accuracy: 0.7372\n",
            "Epoch 33/40\n",
            "32/32 [==============================] - 12s 376ms/step - loss: 0.3884 - accuracy: 0.8350 - val_loss: 0.5716 - val_accuracy: 0.7505\n",
            "Epoch 34/40\n",
            "32/32 [==============================] - 7s 218ms/step - loss: 0.3682 - accuracy: 0.8530 - val_loss: 0.5781 - val_accuracy: 0.7453\n",
            "Epoch 35/40\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.3338 - accuracy: 0.8770 - val_loss: 0.5913 - val_accuracy: 0.7564\n",
            "Epoch 36/40\n",
            "32/32 [==============================] - 7s 219ms/step - loss: 0.3278 - accuracy: 0.8800 - val_loss: 0.7307 - val_accuracy: 0.7343\n",
            "Epoch 37/40\n",
            "32/32 [==============================] - 12s 378ms/step - loss: 0.2891 - accuracy: 0.8890 - val_loss: 0.6499 - val_accuracy: 0.7452\n",
            "Epoch 38/40\n",
            "32/32 [==============================] - 12s 376ms/step - loss: 0.2567 - accuracy: 0.9110 - val_loss: 0.7347 - val_accuracy: 0.7405\n",
            "Epoch 39/40\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.3007 - accuracy: 0.8870 - val_loss: 0.5702 - val_accuracy: 0.7488\n",
            "Epoch 40/40\n",
            "32/32 [==============================] - 12s 388ms/step - loss: 0.2502 - accuracy: 0.9130 - val_loss: 0.7391 - val_accuracy: 0.7128\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"premodel2.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "# Model Fit\n",
        "Pre_Model_2 =  model.fit(x_train, y_train, \n",
        "                     epochs=40, \n",
        "                     batch_size=32, \n",
        "                     validation_data=(x_val, y_val),\n",
        "                     callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB4IowBy6-q3"
      },
      "source": [
        "Visualizing Training and Validation Loss/Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTaDBZ8u7IcX"
      },
      "source": [
        "Loading the Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gapl9D0j7Zbm"
      },
      "source": [
        "Limiting the size of the test samples to 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8I75npY7Kt9"
      },
      "outputs": [],
      "source": [
        "test_dir = os.path.join(imdb_dir, 'test')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(test_dir, label_type)\n",
        "    for fname in sorted(os.listdir(dir_name)):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)[:5000]\n",
        "y_test = np.asarray(labels)[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09EBM5uy7RrR"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efZZs08c7TeH",
        "outputId": "c2a3e747-0972-44c8-e7eb-03b232544c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 4s 20ms/step - loss: 0.4401 - accuracy: 0.7978\n",
            "Loss: 0.440\n",
            "Accuracy: 0.798\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('premodel2.keras')\n",
        "PreModel2_Results = test_model.evaluate(x_test,y_test)\n",
        "print(f'Loss: {PreModel2_Results[0]:.3f}')\n",
        "print(f'Accuracy: {PreModel2_Results[1]:.3f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VX4TlPc5-cfA"
      },
      "source": [
        "The accuracy thus achieved with 1000 training samples and a complex network architecture than the prior model led to a spike in accuracy to 79.8% which is almost 80%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67Rdt22L-qVO"
      },
      "source": [
        "### ***PreTrained Model 3 with 10000 Training Samples***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO3jGSSg-u_I",
        "outputId": "49f34837-628f-4a04-d076-792ab5755f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 87393 unique tokens.\n",
            "Shape of data tensor: (25000, 150)\n",
            "Shape of label tensor: (25000,)\n"
          ]
        }
      ],
      "source": [
        "maxlen = 150  # cutting off reviews after 150 words\n",
        "training_samples = 10000  # training on 10000 samples\n",
        "validation_samples = 10000  # validating on 10000 samples\n",
        "max_words = 10000  # considering the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Splitting the data into a training set and a validation set\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIUsSQWL_Fyg"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "# Compiling the Model\n",
        "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM6QsGPM_aWp"
      },
      "source": [
        "Looking at the Model Sumamry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0zDQ244_b78",
        "outputId": "be7d519f-12f7-42ab-fa97-2103e18ece7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 150, 100)          1000000   \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 150, 64)           42240     \n",
            "                                                                 \n",
            " lstm_20 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,056,833\n",
            "Trainable params: 56,833\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiU_eJD6_f-S"
      },
      "source": [
        "Running the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIFuAt9-_hQ2",
        "outputId": "b006705b-a88e-444e-dd7b-3c3484bc6474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "157/157 [==============================] - 235s 1s/step - loss: 0.6935 - accuracy: 0.5157 - val_loss: 0.6891 - val_accuracy: 0.5328\n",
            "Epoch 2/40\n",
            "157/157 [==============================] - 223s 1s/step - loss: 0.6831 - accuracy: 0.5582 - val_loss: 0.6810 - val_accuracy: 0.5731\n",
            "Epoch 3/40\n",
            "157/157 [==============================] - 222s 1s/step - loss: 0.6694 - accuracy: 0.5886 - val_loss: 0.6528 - val_accuracy: 0.6110\n",
            "Epoch 4/40\n",
            "157/157 [==============================] - 230s 1s/step - loss: 0.6435 - accuracy: 0.6310 - val_loss: 0.6670 - val_accuracy: 0.5759\n",
            "Epoch 5/40\n",
            "157/157 [==============================] - 231s 1s/step - loss: 0.6297 - accuracy: 0.6450 - val_loss: 0.6101 - val_accuracy: 0.6671\n",
            "Epoch 6/40\n",
            "157/157 [==============================] - 232s 1s/step - loss: 0.5964 - accuracy: 0.6802 - val_loss: 0.5902 - val_accuracy: 0.6886\n",
            "Epoch 7/40\n",
            "157/157 [==============================] - 229s 1s/step - loss: 0.5876 - accuracy: 0.6899 - val_loss: 0.5835 - val_accuracy: 0.6947\n",
            "Epoch 8/40\n",
            "157/157 [==============================] - 226s 1s/step - loss: 0.5525 - accuracy: 0.7183 - val_loss: 0.5490 - val_accuracy: 0.7203\n",
            "Epoch 9/40\n",
            "157/157 [==============================] - 226s 1s/step - loss: 0.5487 - accuracy: 0.7256 - val_loss: 0.5816 - val_accuracy: 0.6980\n",
            "Epoch 10/40\n",
            "157/157 [==============================] - 225s 1s/step - loss: 0.5230 - accuracy: 0.7388 - val_loss: 0.5250 - val_accuracy: 0.7366\n",
            "Epoch 11/40\n",
            "157/157 [==============================] - 226s 1s/step - loss: 0.4985 - accuracy: 0.7582 - val_loss: 0.6056 - val_accuracy: 0.6908\n",
            "Epoch 12/40\n",
            "157/157 [==============================] - 225s 1s/step - loss: 0.4780 - accuracy: 0.7696 - val_loss: 0.5308 - val_accuracy: 0.7300\n",
            "Epoch 13/40\n",
            "157/157 [==============================] - 221s 1s/step - loss: 0.4597 - accuracy: 0.7845 - val_loss: 0.5291 - val_accuracy: 0.7494\n",
            "Epoch 14/40\n",
            "157/157 [==============================] - 228s 1s/step - loss: 0.4464 - accuracy: 0.7921 - val_loss: 0.4988 - val_accuracy: 0.7627\n",
            "Epoch 15/40\n",
            "157/157 [==============================] - 220s 1s/step - loss: 0.4236 - accuracy: 0.8004 - val_loss: 0.5256 - val_accuracy: 0.7469\n",
            "Epoch 16/40\n",
            "157/157 [==============================] - 222s 1s/step - loss: 0.4078 - accuracy: 0.8155 - val_loss: 0.4986 - val_accuracy: 0.7827\n",
            "Epoch 17/40\n",
            "157/157 [==============================] - 230s 1s/step - loss: 0.3917 - accuracy: 0.8259 - val_loss: 0.5195 - val_accuracy: 0.7569\n",
            "Epoch 18/40\n",
            "157/157 [==============================] - 234s 1s/step - loss: 0.3792 - accuracy: 0.8254 - val_loss: 0.5098 - val_accuracy: 0.7510\n",
            "Epoch 19/40\n",
            "157/157 [==============================] - 228s 1s/step - loss: 0.3683 - accuracy: 0.8314 - val_loss: 0.4746 - val_accuracy: 0.7808\n",
            "Epoch 20/40\n",
            "157/157 [==============================] - 233s 1s/step - loss: 0.3505 - accuracy: 0.8477 - val_loss: 0.6889 - val_accuracy: 0.7294\n",
            "Epoch 21/40\n",
            "157/157 [==============================] - 236s 2s/step - loss: 0.3495 - accuracy: 0.8413 - val_loss: 0.5001 - val_accuracy: 0.7805\n",
            "Epoch 22/40\n",
            "157/157 [==============================] - 233s 1s/step - loss: 0.3371 - accuracy: 0.8494 - val_loss: 0.6432 - val_accuracy: 0.7311\n",
            "Epoch 23/40\n",
            "157/157 [==============================] - 241s 2s/step - loss: 0.3229 - accuracy: 0.8611 - val_loss: 0.5014 - val_accuracy: 0.7864\n",
            "Epoch 24/40\n",
            "157/157 [==============================] - 236s 2s/step - loss: 0.3206 - accuracy: 0.8622 - val_loss: 0.5025 - val_accuracy: 0.7897\n",
            "Epoch 25/40\n",
            "157/157 [==============================] - 240s 2s/step - loss: 0.2937 - accuracy: 0.8772 - val_loss: 0.5294 - val_accuracy: 0.7831\n",
            "Epoch 26/40\n",
            "157/157 [==============================] - 235s 1s/step - loss: 0.3007 - accuracy: 0.8731 - val_loss: 0.5001 - val_accuracy: 0.7875\n",
            "Epoch 27/40\n",
            "157/157 [==============================] - 231s 1s/step - loss: 0.2925 - accuracy: 0.8729 - val_loss: 0.5571 - val_accuracy: 0.7759\n",
            "Epoch 28/40\n",
            "157/157 [==============================] - 231s 1s/step - loss: 0.2795 - accuracy: 0.8813 - val_loss: 0.5527 - val_accuracy: 0.7878\n",
            "Epoch 29/40\n",
            "157/157 [==============================] - 223s 1s/step - loss: 0.2791 - accuracy: 0.8816 - val_loss: 0.6115 - val_accuracy: 0.7689\n",
            "Epoch 30/40\n",
            "157/157 [==============================] - 227s 1s/step - loss: 0.2592 - accuracy: 0.8899 - val_loss: 0.5656 - val_accuracy: 0.7935\n",
            "Epoch 31/40\n",
            "157/157 [==============================] - 226s 1s/step - loss: 0.2550 - accuracy: 0.8925 - val_loss: 0.5366 - val_accuracy: 0.7883\n",
            "Epoch 32/40\n",
            "157/157 [==============================] - 225s 1s/step - loss: 0.2544 - accuracy: 0.8938 - val_loss: 0.5491 - val_accuracy: 0.7865\n",
            "Epoch 33/40\n",
            "157/157 [==============================] - 223s 1s/step - loss: 0.2437 - accuracy: 0.8998 - val_loss: 0.5912 - val_accuracy: 0.7867\n",
            "Epoch 34/40\n",
            "157/157 [==============================] - 227s 1s/step - loss: 0.2444 - accuracy: 0.8978 - val_loss: 0.5425 - val_accuracy: 0.7928\n",
            "Epoch 35/40\n",
            "157/157 [==============================] - 229s 1s/step - loss: 0.2226 - accuracy: 0.9095 - val_loss: 0.5667 - val_accuracy: 0.7848\n",
            "Epoch 36/40\n",
            "157/157 [==============================] - 233s 1s/step - loss: 0.2331 - accuracy: 0.9007 - val_loss: 0.6124 - val_accuracy: 0.7819\n",
            "Epoch 37/40\n",
            "157/157 [==============================] - 225s 1s/step - loss: 0.2408 - accuracy: 0.8983 - val_loss: 0.5621 - val_accuracy: 0.7897\n",
            "Epoch 38/40\n",
            "157/157 [==============================] - 212s 1s/step - loss: 0.2324 - accuracy: 0.9024 - val_loss: 0.5807 - val_accuracy: 0.7904\n",
            "Epoch 39/40\n",
            "157/157 [==============================] - 213s 1s/step - loss: 0.2105 - accuracy: 0.9115 - val_loss: 0.6921 - val_accuracy: 0.7710\n",
            "Epoch 40/40\n",
            "157/157 [==============================] - 216s 1s/step - loss: 0.2017 - accuracy: 0.9182 - val_loss: 0.6244 - val_accuracy: 0.7930\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"premodel3.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "# Model Fit\n",
        "Pre_Model_3 =  model.fit(x_train, y_train, \n",
        "                     epochs=40, \n",
        "                     batch_size=64, \n",
        "                     validation_data=(x_val, y_val),\n",
        "                     callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpfvaiSW_qBg"
      },
      "source": [
        "Visualizing the Training and Validation Loss/Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3SpvzF8ADUA",
        "outputId": "0435323d-0666-4c12-b07e-04647f6fd3aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 15s 90ms/step - loss: 1.0130 - accuracy: 0.5244\n",
            "Loss: 1.013\n",
            "Accuracy: 0.524\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('premodel3.keras')\n",
        "PreModel3_Results = test_model.evaluate(x_test,y_test)\n",
        "print(f'Loss: {PreModel3_Results[0]:.3f}')\n",
        "print(f'Accuracy: {PreModel3_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiAzZ9M2zxXf"
      },
      "source": [
        "Upon continous experiments and changing the network this was the best accuracy thus achieved when the training sample size was set to 10000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4YWyUudz42W"
      },
      "source": [
        "### ***PreModel 4 with Training Samples of 15000***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1qaqTKCz5NX",
        "outputId": "b39848af-200e-468d-c109-1aaccac97a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 150)\n",
            "Shape of label tensor: (25000,)\n"
          ]
        }
      ],
      "source": [
        "maxlen = 150  # cutting off reviews after 150 words\n",
        "training_samples = 15000  # training on 15000 samples\n",
        "validation_samples = 10000  # validating on 10000 samples\n",
        "max_words = 10000  # considering the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Splitting the data into a training set and a validation set\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq1gugRTz-V7"
      },
      "source": [
        "Building the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64vYa-XYz-pu"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(LSTM(128))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "# Compiling the Model\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPdxMMfx0bfz"
      },
      "source": [
        "Looking at the Summary of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKPZnKNv0ep7",
        "outputId": "15699bfc-6f5b-440e-b386-96f6aa883c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 150, 100)          1000000   \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 150, 256)          365568    \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 150, 256)          0         \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 150, 128)          197120    \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 150, 128)          0         \n",
            "                                                                 \n",
            " lstm_23 (LSTM)              (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,727,553\n",
            "Trainable params: 727,553\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGcIjt3t0gyD"
      },
      "source": [
        "Running the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK8mEy5O0iUx",
        "outputId": "2710eaa4-3303-410b-c983-a7efdad2755c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "235/235 [==============================] - 18s 44ms/step - loss: 0.6943 - accuracy: 0.5040 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 2/40\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.6940 - accuracy: 0.4973 - val_loss: 0.6935 - val_accuracy: 0.5029\n",
            "Epoch 3/40\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.6935 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.5034\n",
            "Epoch 4/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6934 - accuracy: 0.5046 - val_loss: 0.6932 - val_accuracy: 0.5028\n",
            "Epoch 5/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6936 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5033\n",
            "Epoch 6/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6931 - accuracy: 0.5120 - val_loss: 0.6932 - val_accuracy: 0.4985\n",
            "Epoch 7/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6931 - accuracy: 0.5115 - val_loss: 0.6935 - val_accuracy: 0.5033\n",
            "Epoch 8/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6930 - accuracy: 0.5048 - val_loss: 0.6932 - val_accuracy: 0.4965\n",
            "Epoch 9/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6923 - accuracy: 0.5143 - val_loss: 0.6950 - val_accuracy: 0.4978\n",
            "Epoch 10/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6944 - val_accuracy: 0.5054\n",
            "Epoch 11/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6912 - accuracy: 0.5232 - val_loss: 0.6936 - val_accuracy: 0.4987\n",
            "Epoch 12/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6910 - accuracy: 0.5300 - val_loss: 0.6952 - val_accuracy: 0.5010\n",
            "Epoch 13/40\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.6900 - accuracy: 0.5332 - val_loss: 0.6954 - val_accuracy: 0.5023\n",
            "Epoch 14/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6887 - accuracy: 0.5383 - val_loss: 0.6968 - val_accuracy: 0.5040\n",
            "Epoch 15/40\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.6873 - accuracy: 0.5386 - val_loss: 0.6999 - val_accuracy: 0.5033\n",
            "Epoch 16/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6856 - accuracy: 0.5474 - val_loss: 0.7071 - val_accuracy: 0.5006\n",
            "Epoch 17/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6840 - accuracy: 0.5557 - val_loss: 0.7009 - val_accuracy: 0.5041\n",
            "Epoch 18/40\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.6810 - accuracy: 0.5611 - val_loss: 0.7015 - val_accuracy: 0.5012\n",
            "Epoch 19/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6787 - accuracy: 0.5665 - val_loss: 0.6993 - val_accuracy: 0.5012\n",
            "Epoch 20/40\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.6760 - accuracy: 0.5723 - val_loss: 0.7099 - val_accuracy: 0.4999\n",
            "Epoch 21/40\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.6707 - accuracy: 0.5844 - val_loss: 0.7055 - val_accuracy: 0.5018\n",
            "Epoch 22/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6664 - accuracy: 0.5923 - val_loss: 0.7287 - val_accuracy: 0.5024\n",
            "Epoch 23/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6638 - accuracy: 0.5951 - val_loss: 0.7367 - val_accuracy: 0.5007\n",
            "Epoch 24/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6585 - accuracy: 0.5995 - val_loss: 0.7365 - val_accuracy: 0.4975\n",
            "Epoch 25/40\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.6521 - accuracy: 0.6137 - val_loss: 0.7266 - val_accuracy: 0.5059\n",
            "Epoch 26/40\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.6444 - accuracy: 0.6214 - val_loss: 0.7528 - val_accuracy: 0.5013\n",
            "Epoch 27/40\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.6400 - accuracy: 0.6313 - val_loss: 0.7346 - val_accuracy: 0.5047\n",
            "Epoch 28/40\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.6289 - accuracy: 0.6439 - val_loss: 0.7739 - val_accuracy: 0.5040\n",
            "Epoch 29/40\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.6199 - accuracy: 0.6535 - val_loss: 0.7898 - val_accuracy: 0.5021\n",
            "Epoch 30/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.6061 - accuracy: 0.6661 - val_loss: 0.8249 - val_accuracy: 0.4992\n",
            "Epoch 31/40\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.5955 - accuracy: 0.6791 - val_loss: 0.7845 - val_accuracy: 0.5017\n",
            "Epoch 32/40\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.5824 - accuracy: 0.6907 - val_loss: 0.7924 - val_accuracy: 0.5018\n",
            "Epoch 33/40\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.5646 - accuracy: 0.7023 - val_loss: 0.8557 - val_accuracy: 0.5047\n",
            "Epoch 34/40\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.5517 - accuracy: 0.7169 - val_loss: 0.8700 - val_accuracy: 0.4978\n",
            "Epoch 35/40\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.5355 - accuracy: 0.7277 - val_loss: 0.8985 - val_accuracy: 0.5012\n",
            "Epoch 36/40\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.5185 - accuracy: 0.7381 - val_loss: 0.8650 - val_accuracy: 0.4963\n",
            "Epoch 37/40\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 0.5037 - accuracy: 0.7482 - val_loss: 0.9126 - val_accuracy: 0.4962\n",
            "Epoch 38/40\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.4835 - accuracy: 0.7617 - val_loss: 0.9318 - val_accuracy: 0.5003\n",
            "Epoch 39/40\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.4701 - accuracy: 0.7695 - val_loss: 1.0781 - val_accuracy: 0.5038\n",
            "Epoch 40/40\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.4471 - accuracy: 0.7867 - val_loss: 1.0200 - val_accuracy: 0.5041\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"premodel4.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "# Model Fit\n",
        "Pre_Model_4 =  model.fit(x_train, y_train, \n",
        "                     epochs=40, \n",
        "                     batch_size=64, \n",
        "                     validation_data=(x_val, y_val),\n",
        "                     callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQKHTYD31glm"
      },
      "source": [
        "Visualizing the Training and Validation Loss/Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-fpkJPz10Do"
      },
      "source": [
        "Evaluating the Performance on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHZ1hI601245",
        "outputId": "f417b877-5756-4eb7-a84d-519f6c08730c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 11ms/step - loss: 0.6961 - accuracy: 0.3738\n",
            "Loss: 0.696\n",
            "Accuracy: 0.374\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('premodel4.keras')\n",
        "PreModel4_Results = test_model.evaluate(x_test,y_test)\n",
        "print(f'Loss: {PreModel4_Results[0]:.3f}')\n",
        "print(f'Accuracy: {PreModel4_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiLG6WDl40W6"
      },
      "source": [
        "From the point where we started increasing the training samples we also started increasing the complexity of the model, which led to poor performance on the test set, so we are trying to reduce the complexity in the next model to see if it generalizes well on the unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJYlCKZY4zj2"
      },
      "source": [
        "### ***PreModel 5 Reducing the complexity in the model, 15000 Training Samples***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMCzKKgt26D1"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "# Compiling the Model\n",
        "rmsprop = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNCa8Nb15MTd"
      },
      "source": [
        "Looking at the summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUpq9IDK3xMB",
        "outputId": "f4416d38-75ad-49c7-b758-eacc5aefe1ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 150, 100)          1000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               117248    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,150,529\n",
            "Trainable params: 150,529\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJgrdAAv5OeP"
      },
      "source": [
        "Running the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcwgHtQ83zNG",
        "outputId": "9d60c760-76ae-4b1a-e4e7-dbcb4cf2a675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "235/235 [==============================] - 100s 400ms/step - loss: 0.6276 - accuracy: 0.6518 - val_loss: 0.5723 - val_accuracy: 0.7106\n",
            "Epoch 2/40\n",
            "235/235 [==============================] - 91s 389ms/step - loss: 0.5302 - accuracy: 0.7471 - val_loss: 0.5397 - val_accuracy: 0.7140\n",
            "Epoch 3/40\n",
            "235/235 [==============================] - 119s 506ms/step - loss: 0.4621 - accuracy: 0.7919 - val_loss: 0.4353 - val_accuracy: 0.8042\n",
            "Epoch 4/40\n",
            "235/235 [==============================] - 132s 564ms/step - loss: 0.4183 - accuracy: 0.8090 - val_loss: 0.4062 - val_accuracy: 0.8198\n",
            "Epoch 5/40\n",
            "235/235 [==============================] - 92s 394ms/step - loss: 0.3908 - accuracy: 0.8235 - val_loss: 0.3892 - val_accuracy: 0.8290\n",
            "Epoch 6/40\n",
            "235/235 [==============================] - 92s 394ms/step - loss: 0.3665 - accuracy: 0.8397 - val_loss: 0.3609 - val_accuracy: 0.8405\n",
            "Epoch 7/40\n",
            "235/235 [==============================] - 93s 398ms/step - loss: 0.3418 - accuracy: 0.8496 - val_loss: 0.3751 - val_accuracy: 0.8348\n",
            "Epoch 8/40\n",
            "235/235 [==============================] - 89s 378ms/step - loss: 0.3264 - accuracy: 0.8598 - val_loss: 0.3442 - val_accuracy: 0.8526\n",
            "Epoch 9/40\n",
            "235/235 [==============================] - 93s 396ms/step - loss: 0.3082 - accuracy: 0.8679 - val_loss: 0.3672 - val_accuracy: 0.8434\n",
            "Epoch 10/40\n",
            "235/235 [==============================] - 91s 387ms/step - loss: 0.2896 - accuracy: 0.8776 - val_loss: 0.3560 - val_accuracy: 0.8510\n",
            "Epoch 11/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.2761 - accuracy: 0.8802 - val_loss: 0.3367 - val_accuracy: 0.8528\n",
            "Epoch 12/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.2584 - accuracy: 0.8929 - val_loss: 0.3467 - val_accuracy: 0.8520\n",
            "Epoch 13/40\n",
            "235/235 [==============================] - 91s 388ms/step - loss: 0.2409 - accuracy: 0.8981 - val_loss: 0.3903 - val_accuracy: 0.8280\n",
            "Epoch 14/40\n",
            "235/235 [==============================] - 92s 393ms/step - loss: 0.2253 - accuracy: 0.9068 - val_loss: 0.4556 - val_accuracy: 0.8250\n",
            "Epoch 15/40\n",
            "235/235 [==============================] - 90s 384ms/step - loss: 0.2104 - accuracy: 0.9143 - val_loss: 0.5268 - val_accuracy: 0.8122\n",
            "Epoch 16/40\n",
            "235/235 [==============================] - 91s 389ms/step - loss: 0.1876 - accuracy: 0.9235 - val_loss: 0.3793 - val_accuracy: 0.8542\n",
            "Epoch 17/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.1699 - accuracy: 0.9296 - val_loss: 0.6581 - val_accuracy: 0.8051\n",
            "Epoch 18/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.1545 - accuracy: 0.9386 - val_loss: 0.4598 - val_accuracy: 0.8476\n",
            "Epoch 19/40\n",
            "235/235 [==============================] - 89s 379ms/step - loss: 0.1364 - accuracy: 0.9448 - val_loss: 0.5324 - val_accuracy: 0.8539\n",
            "Epoch 20/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.1254 - accuracy: 0.9494 - val_loss: 0.5129 - val_accuracy: 0.8525\n",
            "Epoch 21/40\n",
            "235/235 [==============================] - 92s 391ms/step - loss: 0.1070 - accuracy: 0.9581 - val_loss: 0.6613 - val_accuracy: 0.8350\n",
            "Epoch 22/40\n",
            "235/235 [==============================] - 91s 387ms/step - loss: 0.0911 - accuracy: 0.9637 - val_loss: 0.6192 - val_accuracy: 0.8517\n",
            "Epoch 23/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.0784 - accuracy: 0.9684 - val_loss: 0.6758 - val_accuracy: 0.8465\n",
            "Epoch 24/40\n",
            "235/235 [==============================] - 98s 416ms/step - loss: 0.0682 - accuracy: 0.9747 - val_loss: 0.7545 - val_accuracy: 0.8456\n",
            "Epoch 25/40\n",
            "235/235 [==============================] - 92s 391ms/step - loss: 0.0612 - accuracy: 0.9769 - val_loss: 0.7586 - val_accuracy: 0.8423\n",
            "Epoch 26/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.0553 - accuracy: 0.9784 - val_loss: 0.7493 - val_accuracy: 0.8422\n",
            "Epoch 27/40\n",
            "235/235 [==============================] - 94s 398ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.8722 - val_accuracy: 0.8441\n",
            "Epoch 28/40\n",
            "235/235 [==============================] - 92s 393ms/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 0.9559 - val_accuracy: 0.8405\n",
            "Epoch 29/40\n",
            "235/235 [==============================] - 92s 393ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 1.1417 - val_accuracy: 0.8348\n",
            "Epoch 30/40\n",
            "235/235 [==============================] - 91s 387ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 1.0128 - val_accuracy: 0.8443\n",
            "Epoch 31/40\n",
            "235/235 [==============================] - 92s 391ms/step - loss: 0.0309 - accuracy: 0.9884 - val_loss: 1.0214 - val_accuracy: 0.8442\n",
            "Epoch 32/40\n",
            "235/235 [==============================] - 92s 392ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 1.1422 - val_accuracy: 0.8279\n",
            "Epoch 33/40\n",
            "235/235 [==============================] - 92s 393ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 1.0459 - val_accuracy: 0.8458\n",
            "Epoch 34/40\n",
            "235/235 [==============================] - 92s 391ms/step - loss: 0.0313 - accuracy: 0.9894 - val_loss: 1.1482 - val_accuracy: 0.8391\n",
            "Epoch 35/40\n",
            "235/235 [==============================] - 93s 397ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 1.0811 - val_accuracy: 0.8431\n",
            "Epoch 36/40\n",
            "235/235 [==============================] - 91s 389ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 1.1402 - val_accuracy: 0.8424\n",
            "Epoch 37/40\n",
            "235/235 [==============================] - 91s 386ms/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 1.1539 - val_accuracy: 0.8412\n",
            "Epoch 38/40\n",
            "235/235 [==============================] - 91s 390ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 1.0782 - val_accuracy: 0.8462\n",
            "Epoch 39/40\n",
            "235/235 [==============================] - 91s 389ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 1.1253 - val_accuracy: 0.8483\n",
            "Epoch 40/40\n",
            "235/235 [==============================] - 91s 389ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 1.3015 - val_accuracy: 0.8500\n"
          ]
        }
      ],
      "source": [
        "# Setting Callbacks\n",
        "callbacks = ModelCheckpoint(\n",
        "            filepath= \"premodel5.keras\",\n",
        "            save_best_only= True,\n",
        "            monitor= \"val_loss\"\n",
        "            )\n",
        "\n",
        "# Model Fit\n",
        "Pre_Model_5 =  model.fit(x_train, y_train, \n",
        "                     epochs=40, \n",
        "                     batch_size=64, \n",
        "                     validation_data=(x_val, y_val),\n",
        "                     callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiPCpeKd5Qhk"
      },
      "source": [
        "Visualizing the Training and Validation Loss/Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrFAKQOk5YdB"
      },
      "source": [
        "Evaluating the performance of the model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnOz0qEg5cWl",
        "outputId": "1e4d510d-92d7-484b-a97b-785e51252f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 19s 109ms/step - loss: 0.3320 - accuracy: 0.8508\n",
            "Loss: 0.332\n",
            "Accuracy: 0.851\n"
          ]
        }
      ],
      "source": [
        "test_model = load_model('premodel5.keras')\n",
        "PreModel5_Results = test_model.evaluate(x_test,y_test)\n",
        "print(f'Loss: {PreModel5_Results[0]:.3f}')\n",
        "print(f'Accuracy: {PreModel5_Results[1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DIQef6sG1VT"
      },
      "source": [
        "This seems to be a good performance than compared to the complex architecture that we built before for the same training sample size. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VDetroYeUNTd"
      },
      "source": [
        "Among the pre-trained models, PreModel 5 stood out as the best performer. Despite its less complex network architecture, it achieved better results compared to other models. The underfitting observed in most of the models indicated a lack of pattern learning and understanding of sentiments, resulting in poor performance on unseen data. However, PreModel 5 successfully learned from the training data and demonstrated superior performance among the pre-trained models."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rk4vjyGzVGov"
      },
      "source": [
        "### **Conclusion**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H4SvgnaDVP_L"
      },
      "source": [
        "\n",
        "In the base models, different training sample sizes were evaluated, and it was observed that they performed well without underfitting. By fine-tuning hyperparameters, such as learning rate, embedding vector dimension, Conv1D layers, Dense layers, nodes, and dropout rate, the best performance of 92% accuracy was achieved. The evaluation of pre-trained models revealed that complex networks may not always improve generalization, as simple models can sometimes outperform others. It is important to monitor and adjust for underfitting or overfitting and fine-tune parameters accordingly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
